{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8597ca69",
   "metadata": {},
   "source": [
    "# ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import scipy  #Used to upsample our image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef863be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c299cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'C:\\\\Users\\\\user1\\\\Desktop\\\\DISSERTATION\\\\archive\\\\cell_images\\\\cell_images'\n",
    "SIZE = 224\n",
    "dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.  \n",
    "label = []  #Placeholders to define add labels. We will add 1 to all parasitized images and 0 to uninfected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized_images = os.listdir(image_directory + '\\\\Parasitized2/')\n",
    "for i, image_name in enumerate(parasitized_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    \n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_directory + '\\\\Parasitized2/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36552170",
   "metadata": {},
   "outputs": [],
   "source": [
    "uninfected_images = os.listdir(image_directory + '\\\\Uninfected2/')\n",
    "for i, image_name in enumerate(uninfected_images):\n",
    "    if (image_name.split('.')[1] == 'png'):\n",
    "        image = cv2.imread(image_directory + '\\\\Uninfected2/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)\n",
    "\n",
    "X_train = X_train /255.\n",
    "X_test = X_test /255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761879bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(224, 224, 3)):\n",
    "    # Load VGG16 model with ImageNet weights\n",
    "    vgg = vgg16.VGG16(weights='C:\\\\Users\\\\user1\\\\Desktop\\\\DISSERTATION\\\\vgg16_weights_tf_dim_ordering_tf_kernels_notop (1).h5', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze layers up to block4_pool\n",
    "    for layer in vgg.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = vgg.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(vgg.input, x)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model(input_shape=(224, 224, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, epochs=1, verbose = 1, \n",
    "                    validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bddf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy on the test data\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n",
    "#Test on single image.\n",
    "n=10  #Select the index of image to be loaded for testing\n",
    "img = X_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "print(\"The prediction for this image is: \", np.argmax(model.predict(input_img)))\n",
    "print(\"The actual label for this image is: \", np.argmax(y_test[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "cm=confusion_matrix(np.argmax(y_test, axis=1), y_pred)  \n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10946c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "parasited_image_idx = np.where(y_pred == 1)[0]\n",
    "\n",
    "#Save all images classified as parasited to a directory (optional, makes sense for large data sets)\n",
    "#capture it in memory as an array\n",
    "predicted_as_para=[]\n",
    "for i in parasited_image_idx:\n",
    "    par_img = X_test[i]\n",
    "    #plt.imsave(\"results_classified_as_para/para_\"+str(i)+\".png\", par_img)\n",
    "    predicted_as_para.append(par_img)\n",
    "    \n",
    "predicted_as_para = np.array(predicted_as_para)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c343055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028db5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle  # To add a rectangle overlay to the image\n",
    "from skimage.feature import peak_local_max  # To detect hotspots in 2D images.\n",
    "\n",
    "def plot_heatmap(img):\n",
    "    pred = model.predict(np.expand_dims(img, axis=0))\n",
    "    pred_class = np.argmax(pred)\n",
    "    \n",
    "    # Get weights for all classes from the prediction layer\n",
    "    last_layer_weights = model.layers[-1].get_weights()[0]  # Prediction layer\n",
    "    \n",
    "    # Get weights for the predicted class\n",
    "    last_layer_weights_for_pred = last_layer_weights[:, pred_class]\n",
    "\n",
    "    # Get output from the last conv. layer\n",
    "    last_conv_model = Model(model.input, model.get_layer(\"block5_conv3\").output)\n",
    "    last_conv_output = last_conv_model.predict(np.expand_dims(img, axis=0))  # Predict on the image\n",
    "    last_conv_output = np.squeeze(last_conv_output)  # Squeeze the output to remove single-dimensional entries\n",
    "\n",
    "    # Upsample/resize the last conv. output to the same size as the original image\n",
    "    h = int(img.shape[0] / last_conv_output.shape[0])\n",
    "    w = int(img.shape[1] / last_conv_output.shape[1])\n",
    "    upsampled_last_conv_output = scipy.ndimage.zoom(last_conv_output, (h, w, 1), order=1)\n",
    "\n",
    "    heat_map = np.dot(upsampled_last_conv_output.reshape((img.shape[0] * img.shape[1], 512)), \n",
    "                      last_layer_weights_for_pred).reshape(img.shape[0], img.shape[1])\n",
    "\n",
    "    # Since we have a lot of dark pixels where the edges may be thought of as \n",
    "    # high anomaly, let us drop all heat map values in this region to 0.\n",
    "    # This is an optional step based on the image. \n",
    "    heat_map[img[:, :, 0] == 0] = 0  # All dark pixels outside the object set to 0\n",
    "    \n",
    "    # Detect peaks (hot spots) in the heat map. We will set it to detect maximum 5 peaks.\n",
    "    # with rel threshold of 0.5 (compared to the max peak). \n",
    "    peak_coords = peak_local_max(heat_map, num_peaks=5, threshold_rel=0.5, min_distance=10)\n",
    "\n",
    "    plt.imshow(img.astype('float32').reshape(img.shape[0], img.shape[1], 3))\n",
    "    plt.imshow(heat_map, cmap='jet', alpha=0.30)\n",
    "    for i in range(0, peak_coords.shape[0]):\n",
    "        y = peak_coords[i, 0]\n",
    "        x = peak_coords[i, 1]\n",
    "        plt.gca().add_patch(Rectangle((x-25, y-25), 50, 50, linewidth=1, edgecolor='r', facecolor='none'))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "im = random.randint(0,predicted_as_para.shape[0]-1)\n",
    "heat_map =plot_heatmap(predicted_as_para[im])\n",
    "\n",
    "img = predicted_as_para[im]\n",
    "plt.imshow(predicted_as_para[im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0cbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
